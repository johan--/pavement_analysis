{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import functools\n",
    "from imposm.parser import OSMParser\n",
    "import json\n",
    "from matplotlib import collections as mc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyproj\n",
    "import requests\n",
    "import scipy as sp\n",
    "import rtree\n",
    "# import seaborn as sb\n",
    "from scipy import signal\n",
    "# import shapely\n",
    "import shapely.geometry\n",
    "%pylab inline\n",
    "\n",
    "import data_munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ride Report Method\n",
    "\n",
    "Here, we use the `match` method from the OSRM API with the code modified to return only the endpoints of segments. This allows us to aggregate over OSM segments since the node IDs are uniquely associated with a lat/lon pair given sufficient precision in the returned coordinates. The API recommends not using every single value for the match method, but I'm giving them regardless because it's easier to code. Down-sampling the ride might actually help to smooth some of the rides. (or perhaps not if we accidentally get a jagged part).\n",
    "\n",
    "Currently, I am unsure how to mark up OSM data with bumpiness information, as we have \n",
    "data that look like this in the raw OSM file:\n",
    "\n",
    "\n",
    "``\n",
    "        <way id=\"23642309\" version=\"25\" timestamp=\"2013-12-26T23:03:24Z\" changeset=\"19653154\" uid=\"28775\" user=\"StellanL\">\n",
    "                <nd ref=\"258965973\"/>\n",
    "                <nd ref=\"258023463\"/>\n",
    "                <nd ref=\"736948618\"/>\n",
    "                <nd ref=\"258023391\"/>\n",
    "                <nd ref=\"736948622\"/>\n",
    "                <nd ref=\"930330659\"/>\n",
    "                <nd ref=\"736861978\"/>\n",
    "                <nd ref=\"930330542\"/>\n",
    "                <nd ref=\"930330544\"/>\n",
    "                <nd ref=\"929808660\"/>\n",
    "                <nd ref=\"736934948\"/>\n",
    "                <nd ref=\"930330644\"/>\n",
    "                <nd ref=\"736871567\"/>\n",
    "                <nd ref=\"619628331\"/>\n",
    "                <nd ref=\"740363293\"/>\n",
    "                <nd ref=\"931468900\"/>\n",
    "                <tag k=\"name\" v=\"North Wabash Avenue\"/>\n",
    "                <tag k=\"highway\" v=\"tertiary\"/>\n",
    "                <tag k=\"loc_ref\" v=\"44 E\"/>\n",
    "        </way>\"\n",
    "``\n",
    "\n",
    "\n",
    "My tentative idea is to match up the lat/lons with OSM id using IMPOSM, then find the `nd refs` in the original data and add a property that contains bumpiness information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rides, readings = data_munging.read_raw_data()\n",
    "# This is here temporarily both to create a static dataset and because\n",
    "# some of the newer android readings are bogus and need to be removed.\n",
    "rides = rides.loc[rides['created_at'] < '2016-03-01', :]\n",
    "readings = readings.loc[readings['created_at'] < '2016-03-01', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "readings = data_munging.clean_readings(readings)\n",
    "readings = data_munging.add_proj_to_readings(readings, data_munging.NAD83)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the IP address by linking up to the Docker container running OSRM and pinging it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://162.243.23.60/osrm-chi-vanilla/'\n",
    "url = 'http://172.17.0.2:5000/'\n",
    "nearest_request = url + 'nearest?loc={0},{1}'\n",
    "match_request = url + 'match?loc={0},{1}&t={2}&loc={3},{4}&t={5}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readings_to_match_str(readings):\n",
    "    data_str = '&loc={0},{1}&t={2}'\n",
    "    output_str = ''\n",
    "    elapsed_time = 0\n",
    "    for i, reading in readings.iterrows():\n",
    "        elapsed_time += 1\n",
    "        new_str = data_str.format(str(reading['start_lat']), str(reading['start_lon']), str(elapsed_time))\n",
    "        output_str += new_str\n",
    "    return url + 'match?' + output_str[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "readings_to_match_str(readings.loc[readings['ride_id'] == 128,  :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matched_ride = requests.get(readings_to_match_str(readings.loc[readings['ride_id'] == 128,  :])).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snapped_points =  pd.DataFrame(matched_ride['matchings'][0]['matched_points'], columns=['lat', 'lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = snapped_points.plot(x='lon', y='lat', kind='scatter')\n",
    "readings.loc[readings['ride_id'] == 128,  :].plot(x='start_lon', y='start_lat', kind='scatter', ax=ax)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_reading = readings.loc[0, :]\n",
    "test_match_request = match_request.format(a_reading['start_lat'],\n",
    "                                      a_reading['start_lon'], \n",
    "                                      0,\n",
    "                                      a_reading['end_lat'],\n",
    "                                      a_reading['end_lon'],\n",
    "                                      1)\n",
    "# This does not work because OSRM does not accept floats as times. \n",
    "# test_map_request = map_request.format(*tuple(a_reading[['start_lat', 'start_lon', 'start_time',\n",
    "#                                                 'end_lat', 'end_lon', 'end_time']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_nearest_request = nearest_request.format(a_reading['start_lat'], a_reading['start_lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "osrm_response = requests.get(test_match_request).json()\n",
    "osrm_response['matchings'][0]['matched_points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "osrm_response = requests.get(test_nearest_request).json()\n",
    "osrm_response['mapped_coordinate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "readings['snapped_lat'] = 0\n",
    "readings['snapped_lon'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# total_calls = 0\n",
    "# for i, reading in readings.iterrows():\n",
    "#     nearest_request = nearest_request.format(reading['start_lat'], reading['end_lat'])\n",
    "#     osrm_response = requests.get(osrm_request).json()\n",
    "#     print osrm_response\n",
    "#     total_calls += 1\n",
    "#     if total_calls > 100:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# total_calls = 0\n",
    "# for i, reading in readings.iterrows():\n",
    "#     data = tuple(reading[['start_lat', 'start_lon']])\n",
    "# #     print i\n",
    "# #     print data \n",
    "#     osrm_request = nearest_request.format(*data)\n",
    "#     osrm_response = requests.get(osrm_request).json()\n",
    "#     readings.loc[i, ['snapped_lat', 'snapped_lon']] = osrm_response['mapped_coordinate']\n",
    "# #     print osrm_response\n",
    "#     total_calls += 1\n",
    "#     if total_calls % 1000 == 0:\n",
    "#         print(total_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chi_readings = data_munging.filter_readings_to_chicago(readings)\n",
    "chi_rides = list(set(chi_readings.ride_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_rides = [128, 129, 5.0, 7.0, 131, 133, 34, 169, 16.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ride_id in chi_rides:\n",
    "    if ride_id in bad_rides:\n",
    "        print('ride_id')\n",
    "        try:\n",
    "            print('num readings: ' + str(sum(readings['ride_id'] == ride_id)))\n",
    "        except:\n",
    "            print('we had some issues here lol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for ride_id in chi_rides:\n",
    "#     if pd.notnull(ride_id):\n",
    "#         complete_snapped_points.loc[complete_snapped_points['ride_id'] == ride_id, ['id']] = readings.loc[readings['ride_id'] == ride_id, ['id']]\n",
    "#         print(complete_snapped_points.loc[complete_snapped_points['ride_id'] == ride_id, ['id']])\n",
    "#         print(readings.loc[readings['ride_id'] == ride_id, ['id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_snapped_points = []\n",
    "readings['snapped_lat'] = np.NaN\n",
    "readings['snapped_lon'] = np.NaN\n",
    "for ride_id in chi_rides:\n",
    "    if pd.notnull(ride_id):\n",
    "#         for i, reading in readings.loc[readings['ride_id'] == random_ride_id, :].iterrows():\n",
    "#             ax = plt.plot([reading['start_lon'], reading['end_lon']], [reading['start_lat'], reading['end_lat']])\n",
    "        ax = readings.loc[readings['ride_id'] == ride_id, :].plot(x='start_lon', y='start_lat')\n",
    "        try:\n",
    "            matched_ride = requests.get(readings_to_match_str(readings.loc[readings['ride_id'] == ride_id,  :])).json() \n",
    "            readings.loc[readings['ride_id'] == ride_id, ['snapped_lat', 'snapped_lon']] = matched_ride['matchings'][0]['matched_points']\n",
    "            readings.loc[readings['ride_id'] == ride_id, :].plot(x='snapped_lon', y='snapped_lat', ax=ax)\n",
    "        except:\n",
    "            print('could not snap')\n",
    "        plt.title('Plotting Ride ' + str(ride_id))\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(18.5, 10.5)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all_snapped_points = []\n",
    "# readings['snapped_lat'] = np.NaN\n",
    "# readings['snapped_lon'] = np.NaN\n",
    "# for ride_id in chi_rides:\n",
    "#     if pd.notnull(ride_id):\n",
    "# #         for i, reading in readings.loc[readings['ride_id'] == random_ride_id, :].iterrows():\n",
    "# #             ax = plt.plot([reading['start_lon'], reading['end_lon']], [reading['start_lat'], reading['end_lat']])\n",
    "#         ax = readings.loc[readings['ride_id'] == ride_id, :].plot(x='start_lon', y='start_lat')\n",
    "#         try:\n",
    "#             matched_ride = requests.get(readings_to_match_str(readings.loc[readings['ride_id'] == ride_id,  :])).json() \n",
    "#             readings.loc[readings['ride_id'] == ride_id, ['snapped_lat', 'snapped_lon']] = matched_ride['matchings'][0]['matched_points']\n",
    "#             snapped_points =  pd.DataFrame(matched_ride['matchings'][0]['matched_points'], columns=['lat', 'lon'])\n",
    "#             readings.loc[readings['ride_id'] == 'ride_id', ['snapped_lat', 'snapped_lon']] = matched_ride['matchings'][0]['matched_points']\n",
    "#             readings.loc[readings['ride_id'] == 'ride_id', 'snapped_lon'] = snapped_points['lon']\n",
    "#             snapped_points['ride_id'] = ride_id\n",
    "#             snapped_points['id'] = readings.loc[readings['ride_id'] == ride_id, ['id']]\n",
    "#             snapped_points.plot(x='lon', y='lat', ax=ax)\n",
    "#             print('this thing right here')\n",
    "#             all_snapped_points.append(snapped_points)\n",
    "#         except:\n",
    "#             print('could not snap')\n",
    "#         plt.title('Plotting Ride ' + str(ride_id))\n",
    "#         fig = plt.gcf()\n",
    "#         fig.set_size_inches(18.5, 10.5)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_chi_rides = [i for i in chi_rides if i not in bad_rides]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# complete_snapped_points = pd.concat(all_snapped_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = readings.loc[readings['ride_id'] == 2, :].plot(x='snapped_lon', y='snapped_lat', style='r-')\n",
    "for ride_id in good_chi_rides:\n",
    "    print(ride_id)\n",
    "    try:\n",
    "#         readings.loc[readings['ride_id'] == ride_id, :].plot(x='start_lon', y='start_lat', ax=ax)\n",
    "        readings.loc[readings['ride_id'] == ride_id, :].plot(x='snapped_lon', y='snapped_lat', ax=ax, style='b-')\n",
    "    except:\n",
    "        print('bad')\n",
    "ax = readings.loc[readings['ride_id'] == 2, :].plot(x='snapped_lon', y='snapped_lat', style='r-', ax=ax)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(36, 36)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lat_lons_by_ride = collections.defaultdict(set)\n",
    "# for index, row in readings.iterrows():\n",
    "#     lat_lons_by_ride[tuple(row[['snapped_lat', 'snapped_lon']])].add(row['ride_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# most_common_lat_lons = sorted(lat_lons_by_ride.items(), key=lambda i: len(i[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that we are in fact snapping to the same points across rides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_printed = 0\n",
    "for item in most_common_lat_lons:\n",
    "    total_printed += 1\n",
    "    print item\n",
    "    if total_printed > 300:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "readings['next_snapped_lat'] = np.NaN\n",
    "readings['next_snapped_lon'] = np.NaN\n",
    "for ride_id in good_chi_rides:\n",
    "    next_lat_lon = (np.NaN, np.NaN)\n",
    "    for index, row in reversed(list(readings.loc[readings['ride_id'] == ride_id, :].iterrows())):\n",
    "        readings.loc[index, ['next_snapped_lat', 'next_snapped_lon']] = next_lat_lon\n",
    "        if (row['snapped_lat'], row['snapped_lon']) != next_lat_lon:\n",
    "            next_lat_lon = (row['snapped_lat'], row['snapped_lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "road_bumpiness = collections.defaultdict(list)\n",
    "for index, reading in readings.iterrows():\n",
    "    if reading['gps_mph'] < 30 and reading['gps_mph'] > 3:\n",
    "        osm_segment = [(reading['snapped_lat'], reading['snapped_lon']),\n",
    "                      (reading['next_snapped_lat'], reading['next_snapped_lon'])]\n",
    "        osm_segment = sorted(osm_segment)\n",
    "        if all([lat_lon != (np.NaN, np.NaN) for lat_lon in osm_segment]):\n",
    "            road_bumpiness[tuple(osm_segment)].append(reading['abs_mean_over_speed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sorted_road_bumpiness = sorted(road_bumpiness.items(), key=lambda i: len(i[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agg_road_bumpiness = dict((osm_segment, np.mean(road_bumpiness[osm_segment])) for osm_segment in road_bumpiness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../dat/agg_road_bumpiness.txt', 'w+') as f:\n",
    "    f.write(str(agg_road_bumpiness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../dat/agg_road_bumpiness.txt', 'r') as f:\n",
    "    agg_road_bumpiness = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agg_road_bumpiness = eval(agg_road_bumpiness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_out_na_from_osm_segments(osm_segment):\n",
    "    return np.NaN in osm_segment[0] or np.NaN in osm_segment[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agg_road_bumpiness = dict((osm_segment, agg_road_bumpiness[osm_segment]) for osm_segment in agg_road_bumpiness if not filter_out_na_from_osm_segments(osm_segment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.max(agg_road_bumpiness.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(agg_road_bumpiness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(agg_road_bumpiness.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plasma = cm = plt.get_cmap('plasma')\n",
    "cNorm  = colors.Normalize(vmin=0, vmax=1.0)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=plasma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for osm_segment, bumpiness in agg_road_bumpiness.items():\n",
    "    plt.plot([osm_segment[0][1], osm_segment[1][1]],\n",
    "             [osm_segment[0][0], osm_segment[1][0]],\n",
    "             color=scalarMap.to_rgba(bumpiness))\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# total_calls = 0\n",
    "# for i, reading in readings.iterrows():\n",
    "#     data = tuple(reading[['start_lat', 'start_lon']]) + (0,) + tuple(reading[['end_lat', 'end_lon']]) + (1,)   \n",
    "#     print i\n",
    "#     print data \n",
    "#     osrm_request = map_request.format(*data)\n",
    "#     osrm_response = requests.get(osrm_request).json()\n",
    "#     print osrm_response\n",
    "#     total_calls += 1\n",
    "#     if total_calls > 100:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# total_calls = 0\n",
    "# for i, reading in readings.iterrows():\n",
    "#     data = tuple(reading[['start_lat', 'start_lon']]) + (0,) + tuple(reading[['end_lat', 'end_lon']]) + (1,)   \n",
    "#     print i\n",
    "#     print data \n",
    "#     osrm_request = map_request.format(*data)\n",
    "#     osrm_response = requests.get(osrm_request).json()\n",
    "#     print osrm_response\n",
    "#     total_calls += 1\n",
    "#     if total_calls > 100:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i, reading in readings.iterrows():\n",
    "#     data = tuple(reading[['start_lat', 'start_lon']]) + (0,) + tuple(reading[['end_lat', 'end_lon']]) + (1,)   \n",
    "#     osrm_request = map_request.format(*data)\n",
    "#     osrm_response = requests.get(osrm_request).json()\n",
    "#     print osrm_response\n",
    "#     readings.loc[i, ['snapped_start_lat', 'snapped_start_lon']] = osrm_response['matchings'][0]['matched_points'][0]\n",
    "#     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
